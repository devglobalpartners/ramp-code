{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a generic notebook for viewing model predictions\n",
    "\n",
    "#### First, set up the preliminaries for viewing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # only print errors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RAMP_HOME=/content/drive/MyDrive/code/projects/ramp-staging-test/ramp-staging/colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "RAMP_HOME = os.environ[\"RAMP_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ramp.data_mgmt.data_generator import test_batches_from_gtiff_dirs_with_names\n",
    "from ramp.data_mgmt.display_data import display_img_mask_pred_batch, get_mask_from_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Set your training data location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {RAMP_HOME}/data/TRAIN/myanmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data path\n",
    "DATA_PATH = Path(RAMP_HOME) / \"data/TRAIN/myanmar\"\n",
    "\n",
    "# path to all models built using this dataset\n",
    "ALL_MODELS_PATH = DATA_PATH / \"model-checkpts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"20220826-125633\"\n",
    "!tree {ALL_MODELS_PATH}/{timestamp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Set your saved model location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model path\n",
    "# COMMENT ON MODEL TYPE HERE: multimask, extra augmentation, loss function weighting by class\n",
    "MODEL_PATH = ALL_MODELS_PATH/f\"{timestamp}/model_20220826-125633_002_0.962.tf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Set batchsize, input and output image sizes.\n",
    "\n",
    "Batchsize is whatever number of files you'd like to display in a single image. I recommend keeping batch_size small for good conversion to pdfs (using 'nbconvert' or any other jupyter notebook rendering tool). \n",
    "\n",
    "Numbatches is the total number of image batches you'd like to display. This can be as large as you like. \n",
    "\n",
    "Image sizes should be set to their values during training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample configuration\n",
    "NUMBATCHES = 10 # number of batches to display\n",
    "BATCH_SIZE = 4 # size per batch -- I recommend keeping this small for better pdf output\n",
    "INPUT_IMAGE_SIZE = (256, 256)\n",
    "OUTPUT_IMAGE_SIZE = (256, 256)\n",
    "\n",
    "test_img_dir = str(DATA_PATH / \"valchips\")\n",
    "\n",
    "# mask type. Comment out the type of mask (binary vs. multichannel) that you are not using. \n",
    "test_mask_dir = str(DATA_PATH / \"val-multimasks\")\n",
    "# test_mask_dir = str(DATA_PATH / \"val-binmasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END CONFIGURATION, begin code for viewing model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up batches for display\n",
    "test_batches = test_batches_from_gtiff_dirs_with_names(\n",
    "                                            test_img_dir, \n",
    "                                            test_mask_dir, \n",
    "                                            BATCH_SIZE, \n",
    "                                            INPUT_IMAGE_SIZE, \n",
    "                                            OUTPUT_IMAGE_SIZE)\n",
    "\n",
    "# load model\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding notes\n",
    "\n",
    "#### This notebook uses a data generator that returns the filenames of the chips and masks as well as the chips and masks. \n",
    "\n",
    "You can iterate through batches multiple times to display more results. In this code, I iterate through and display two batches. \n",
    "\n",
    "##### Iterating over batches\n",
    "\n",
    "You have to be a bit careful how you iterate through batches, or you'll get confusing bugs like I did. \n",
    "\n",
    "Iterate through batches using this code:\n",
    "\n",
    "```\n",
    "test_batches = test_batches_from_gtiff_dirs_with_names(\n",
    "                                            test_img_dir, \n",
    "                                            test_mask_dir, \n",
    "                                            BATCH_SIZE, \n",
    "                                            INPUT_IMAGE_SIZE, \n",
    "                                            OUTPUT_IMAGE_SIZE)\n",
    "                                            \n",
    "# these test batches are streaming. Create an iterator for them.\n",
    "iterator = iter(test_batches)\n",
    "batch = iterator.get_next()\n",
    "```\n",
    "\n",
    "When you want to get a new batch, call iterator.get_next() again.\n",
    "\n",
    "##### Structure of data in each batch\n",
    "\n",
    "In each batch, batch[0] contains all the data associated with the image chips. It's a 2-tuple: the first element, batch[0][0], is the image batch tensor, and batch[0][1] is a list of image names in the batch. \n",
    "\n",
    "Batch[1] is data associated with masks: batch[1][0] is the mask batch tensor and batch[1][1] is a list of mask names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one batch from the data generator. \n",
    "iterator = iter(test_batches)\n",
    "batch = iterator.get_next()\n",
    "chips = batch[0][0]\n",
    "masks = batch[1][0]\n",
    "chipnames = batch[0][1] \n",
    "masknames = batch[1][1]\n",
    "prediction = model.predict(chips)\n",
    "\n",
    "# Predictions are one-hot encoded by default. \n",
    "# Binary predictions will have two channels. \n",
    "# Multichannel predictions will have four channels \n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# we flatten the channels (by taking their max) \n",
    "# to make a mask with only 1 channel from the prediction.\n",
    "predmask = get_mask_from_prediction(prediction)\n",
    "print(f\"Sparse prediction shape: {predmask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the output of the trained model.\n",
    "print(\"LIST OF CHIP FILES\")\n",
    "print('\\n'.join([name_tensor.numpy().decode('utf-8') for name_tensor in chipnames]))\n",
    "display_img_mask_pred_batch(chips, masks, predmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_batch(model, iterator):\n",
    "    batch = iterator.get_next()\n",
    "    chips = batch[0][0]\n",
    "    masks = batch[1][0]\n",
    "    chipnames = batch[0][1] \n",
    "    prediction = model.predict(chips)\n",
    "    predmask = get_mask_from_prediction(prediction)\n",
    "    print(\"LIST OF CHIP FILES\")\n",
    "    print('\\n'.join([name_tensor.numpy().decode('utf-8') for name_tensor in chipnames]))\n",
    "    display_img_mask_pred_batch(chips, masks, predmask)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(NUMBATCHES):\n",
    "    display_batch(model, iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
